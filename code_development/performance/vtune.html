

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Example VTune Analysis &mdash; Sigma2/Metacenter documentation  documentation</title>
  

  
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />

  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script src="../../_static/language_data.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    
    <script type="text/javascript" src="../../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../index.html" class="icon icon-home" alt="Documentation Home"> Sigma2/Metacenter documentation
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">News</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://opslog.sigma2.no">Latest changes and events</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.sigma2.no/hardware-status">Hardware live status</a></li>
</ul>
<p class="caption"><span class="caption-text">Getting help</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../getting_help/support_line.html">Support line</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../getting_help/how_to_write_good_support_requests.html">Writing good support requests</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../getting_help/qa-sessions.html">Open Question &amp; Answer Sessions for All Users</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../getting_help/lost_forgotten_password.html">Lost or expiring password</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../getting_help/project_leader_support.html">Project leader support</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../getting_help/advanced_user_support.html">Advanced User Support (AUS)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../getting_help/publish_research_data.html">Publish Research Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../getting_help/course_resources.html">CRaaS - Course Resources as a Service</a></li>
</ul>
<p class="caption"><span class="caption-text">Getting started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../frontpage.html">The Norwegian Academic HPC Services</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../getting_started/applying_account.html">How do I get an HPC account?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../getting_started/applying_resources.html">Applying for computing and storage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../getting_started/training.html">Training material</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../getting_started/getting_started.html">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../getting_started/create_ssh_keys.html">SSH</a></li>
</ul>
<p class="caption"><span class="caption-text">HPC Machines</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../hpc_machines/hardware_overview.html">Overview over our machines</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../hpc_machines/betzy.html">Betzy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../hpc_machines/fram.html">Fram</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../hpc_machines/saga.html">Saga</a></li>
<li class="toctree-l1"><a class="reference external" href="https://hpc-uit.readthedocs.io">Stallo</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../hpc_machines/migration2metacenter.html">Migration to a Metacenter HPC machine</a></li>
</ul>
<p class="caption"><span class="caption-text">Software</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../software/modulescheme.html">Software Module Scheme</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../software/installed_software.html">Installed Software</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../software/containers.html">Running Singularity and Docker containers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../software/appguides.html">Application guides</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../software/userinstallsw.html">How can I, as a user, install software for myself or my project with EasyBuild?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../software/userinstallsw.html#how-can-i-as-user-install-python-packages">How can I as user install Python packages?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../software/licenses.html">Licenses and access policies</a></li>
</ul>
<p class="caption"><span class="caption-text">Jobs</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../jobs/submitting.html">Submitting jobs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../jobs/choosing_job_types.html">Job Types</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../jobs/job_scripts.html">Job Scripts</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../jobs/running-scientific-software.html">Running scientific software</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../jobs/monitoring.html">Monitoring jobs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../jobs/choosing_memory_settings.html">How to choose the right amount of memory</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../jobs/common_job_failures.html">Common job failures</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../jobs/performance.html">How to check the performance and scaling using Arm Performance Reports</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../jobs/interactive_jobs.html">Interactive jobs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../jobs/projects_accounting.html">Projects and accounting</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../jobs/network-access.html">No network access on compute nodes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../jobs/dos_and_donts.html">Dos and Don’ts</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../jobs/guides.html">Guides</a></li>
</ul>
<p class="caption"><span class="caption-text">Files and Storage</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../files_storage/nird.html">NIRD - National Infrastructure for Research Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../files_storage/clusters.html">Storage areas on HPC clusters</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../files_storage/backup.html">Backup on Betzy, Fram, Saga, and NIRD</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../files_storage/sharing_files.html">Data handling and storage policy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../files_storage/file_transfer.html">File transfer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../files_storage/performance.html">Storage performance tuning</a></li>
</ul>
<p class="caption"><span class="caption-text">Code Development</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../building.html">Building scientific software</a></li>
<li class="toctree-l1"><a class="reference internal" href="../compilers.html">Compilers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../performance.html">Performance Analysis and Tuning</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">Sigma2/Metacenter documentation</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>Example VTune Analysis</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            
              <a href="https://github.com/UNINETTSigma2/documentation/blob/master/code_development/performance/vtune.md" class="fa fa-github"> Edit on GitHub</a>
            
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="example-vtune-analysis">
<h1>Example VTune Analysis<a class="headerlink" href="#example-vtune-analysis" title="Permalink to this headline">¶</a></h1>
<p>As an example we use VTune Amplifier to analyze the performance of the
original, and the optimized software package ART - a 3D radiative
transfer solver developed within the <a class="reference external" href="https://www.mn.uio.no/astro/english/research/projects/solaralma/">SolarALMA
project</a>. The
code is written in C++ and consists of two major computational
parts:</p>
<ul class="simple">
<li><p>An equation of state (EOS) solver, which - based on various types of
input data - computes electron density, gas pressure, and
density.</p></li>
<li><p>A nonlinear solver for radiative transfer (RT). This code is based on
a FORTRAN code from 1970 by Robert Kurucz.</p></li>
</ul>
<p>Input data is read from HDF5 files and composed into a set of 3D
Cartesian grids. The two kernels described above are executed
independently for each grid point, with no communication required by
the neighbor cells. In this sense the code is trivially
parallelizable and to find opportunities for optimization we look at
the per-core (call it “sequential”) performance. The optimization
effort has been done within the PRACE Preparatory Access project type
D. For more details about the optimizatoin techniques <a class="reference external" href="https://doi.org/10.5281/zenodo.2633704">consult the
white paper.</a></p>
<div class="section" id="using-vtune-on-fram">
<h2>Using VTune on Fram<a class="headerlink" href="#using-vtune-on-fram" title="Permalink to this headline">¶</a></h2>
<p>First, to use VTune on Fram you need to load the corresponding
software module <code class="docutils literal notranslate"><span class="pre">VTune</span></code>. To list the available versions:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ ml avail VTune

   VTune/2017_update1    VTune/2018_update1    VTune/2018_update3
</pre></div>
</div>
<p>Then load the desired (newest) version</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ ml load VTune/2018_update3
</pre></div>
</div>
<p>To gather information about a code’s performance one needs to execute
the code using the <a class="reference external" href="https://software.intel.com/en-us/vtune-amplifier-help-amplxe-cl-command-syntax"><code class="docutils literal notranslate"><span class="pre">amplxe-cl</span></code>
command</a>. Depending
on the needs, <code class="docutils literal notranslate"><span class="pre">amplxe-cl</span></code> can gather all sorts of performance statistics: FPU
utilization, usage of vector (SIMD) AVX insturctions, instructions per
clock, memory bandwidth, cache utilization, threading level, etc. For
example, to collect general information about the most time-consuming
parts of the code:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ amplxe-cl -collect hotspots ./your-program your-arguments
</pre></div>
</div>
<p>For a complete list of analysis modes please consult the <a class="reference external" href="https://software.intel.com/en-us/vtune-amplifier-help-collect#7A146C04-7E5E-4C41-BAC7-92670C43B4E5">VTune
documentation</a>. A
useful set of performance metrics is gathered by the
<code class="docutils literal notranslate"><span class="pre">hрc-performance</span></code> analysis, which can help to identify opportunities
to optimize CPU, memory, and vectorization level:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ amplxe-cl -collect hpc-performance ./your-program your-arguments
</pre></div>
</div>
<p>A detailed description and the available options for each profiling
mode can be obtained as follows</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ amplxe-cl -help collect hpc-performance

[...]

 To modify the analysis type, use the configuration options (knobs) as
 follows:
 -collect hpc-performance -knob &lt;knobName&gt;=&lt;knobValue&gt;
 Multiple -knob options are allowed and can be followed by additional collect
 action options, as well as global options, if needed.

sampling-interval
[...]

enable-stack-collection
[...]

collect-memory-bandwidth
[...]

dram-bandwidth-limits
[...]

analyze-openmp
[...]
</pre></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">enable-stack-collection</span></code> knob, disabled by default, provides detailed
caller / callee information for each profiled function. It can be very
useful, but might introduce some overhead. We will use it in the
following example.</p>
<p>Collected performance statistics are saved in a subdirectory, by
default in the directory you are running from. For the above example
the results are stored in <code class="docutils literal notranslate"><span class="pre">r000hpc/</span></code>. They can then be compressed and
moved to, e.g., a desktop computer, or they can be analyzed on one of
the Fram login nodes using the VTune Amplifier GUI:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ ssh -Y fram.sigma2.no
$ ml load VTune/2018_update3
$ amplxe-gui
</pre></div>
</div>
<p>Note that running the GUI directly on Fram migh feel sluggish depending
on your network connection.</p>
</div>
<div class="section" id="vtune-analysis">
<h2>VTune analysis<a class="headerlink" href="#vtune-analysis" title="Permalink to this headline">¶</a></h2>
<p>The performance characteristics of the original code are obtained as
follows</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">amplxe</span><span class="o">-</span><span class="n">cl</span> <span class="o">-</span><span class="n">collect</span> <span class="n">hpc</span><span class="o">-</span><span class="n">performance</span> <span class="o">-</span><span class="n">knob</span> <span class="n">enable</span><span class="o">-</span><span class="n">stack</span><span class="o">-</span><span class="n">collection</span><span class="o">=</span><span class="n">true</span> <span class="o">-</span><span class="n">knob</span> <span class="n">collect</span><span class="o">-</span><span class="n">memory</span><span class="o">-</span><span class="n">bandwidth</span><span class="o">=</span><span class="n">false</span> <span class="n">mpirun</span> <span class="o">-</span><span class="n">np</span> <span class="mi">1</span> <span class="o">./</span><span class="n">ART</span><span class="o">.</span><span class="n">x</span>
</pre></div>
</div>
<p>Since we are interested in the “sequential” (per-core) performance, we
only analyze a single MPI rank. The stack collection is enabled. Once
the sampling results are opened in the VTune Amplifier GUI, the
performance summary is presented:</p>
<p><img alt="VTune Summary" src="../../_images/vtune_summary.png" /></p>
<p>The CPU Utilization section shows the total percentage of all
available cores used. Since a single ART process was executed, this
metric is very low (1 out of 64 logical cores are used), but that is
expected. The memory statistics show that ART is compute bound: there
is almost no references to the global memory (DRAM bound 0%). Also the
caches are not very busy. It is clear that most of the run time goes
into CPU instructions.</p>
<p>The FPU utilization report is hence the most interesting one in this
case. It reveals that 90% of the floating point instructions are scalar, i.e.,
the vector units (AVX) are mostly unused. Looking at the top most busy
functions it becomes clear that the time is spent in calls to <code class="docutils literal notranslate"><span class="pre">libm</span></code>
<code class="docutils literal notranslate"><span class="pre">exp</span></code> and <code class="docutils literal notranslate"><span class="pre">log</span></code>.</p>
<p>A closer look at the Bottom-up section of the performance report
reveals the heaviest parts of the code.</p>
<p><img alt="VTune Bottom-up" src="../../_images/vtune_bottomup.png" /></p>
<p>This confirms the previous finding (and adds <code class="docutils literal notranslate"><span class="pre">pow</span></code> to the list of
computationally heavy functions). From the above reports we can
roughly scetch the optimization directions:</p>
<ul class="simple">
<li><p>Re-write the code such that the vectorized math library is used for
<code class="docutils literal notranslate"><span class="pre">exp,</span> <span class="pre">log,</span> <span class="pre">pow</span></code> calls</p></li>
<li><p>Concentrate on the heaviest functions from the Bottom-up list</p></li>
</ul>
</div>
<div class="section" id="the-optimized-code">
<h2>The optimized code<a class="headerlink" href="#the-optimized-code" title="Permalink to this headline">¶</a></h2>
<p>Both GCC and ICC provide an interface to a vectorized math library with
platform-optimized implementations of amongst others
<code class="docutils literal notranslate"><span class="pre">exp,pow,log</span></code>. Intel compiler uses
its own Short Vector Math Library (SVML). The library comes together
with the compiler installation, and there is nothing system-specific
that needs to be done to use it. GCC on the other hand relies on
<code class="docutils literal notranslate"><span class="pre">libmvec</span></code>, which is part of Glibc version 2.22 and higher. This means
that on systems with an older version of Glibc the vectorized math
library is not readily available, regardless of the GCC version. This
is a practical problem, because OS vendors often lag a few years when
it comes to Glibc (e.g., Centos 7.5 comes with version 2.17 released
in the end of 2012). However, it is possible to install a custom Glibc
as a module and use it for user’s code.</p>
<p>As noted in the <a class="reference external" href="https://software.intel.com/en-us/node/524289">documentation of
SVML</a> the vectorized
math library differs from the scalar functions in accuracy.  Scalar
implementations are not the same as the vectorized ones with vector
width of 1. Instead, they follow strict floating-point arithmetic and
are more computationally demanding. GCC is by default conservative
wrt. the floating-point optimizations: vectorized math library is only
enabled with the <code class="docutils literal notranslate"><span class="pre">-ffast-math</span></code> compiletime option. ICC by default uses
relaxed settings (<code class="docutils literal notranslate"><span class="pre">-fp-model</span> <span class="pre">fast=1</span></code>), which allow the compiler to
make calls to low accuracy SVML functions. In addition, SVML also
provides higher accuracy vectorized functions (<code class="docutils literal notranslate"><span class="pre">-fp-model</span> <span class="pre">precise</span></code>).
Vectorization of libm calls can be prohibited with <code class="docutils literal notranslate"><span class="pre">-fp-model</span> <span class="pre">strict</span></code>. With ART the high accuracy is not required, hence we compile
the code with the most relaxed settings.</p>
<p>Vectorization of the code has been performed using <code class="docutils literal notranslate"><span class="pre">#pragma</span> <span class="pre">simd</span></code>
defined by the OpenMP standard. All the heaviest ART functions, and
all floating-point intensive loops have been vectorized using this
method, and VTune was used throughout the process to find new
bottlenecks once the existing ones have been optimized. Below is the
final VTune report of the optimized code compiled using the GCC 8
compiler:</p>
<p><img alt="VTune Summary - Optimized GCC" src="../../_images/vtune_opt_gcc.png" /></p>
<p>and using the Intel 18 compiler:</p>
<p><img alt="VTune Summary - Optimized ICC" src="../../_images/vtune_opt_intel.png" /></p>
<p>Notably, the optimized code utilizes the vector (AVX) units for 87% of
the total FP instructions with GCC, and for 94% of the FP instructions
with the Intel compiler. The capacity of the vector units is used in
85%-90%, which demonstrates that the code is almost fully vectorized.</p>
<p>Compared to the original code, the performance tests have shown that
on a Broadwell-based architecture the optimized code works from 2.5
times faster (RT solver) to 13 times faster (EOS solver) on a single
core. All optimizatoin techniques employed have been described in
detail in <a class="reference external" href="https://doi.org/10.5281/zenodo.2633704">the white paper</a>.</p>
</div>
</div>


           </div>
           
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        
        &copy; Copyright 2020, Sigma2/Metacenter

    </p>
  </div>
    
    
    
    Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>